# üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Pesquisa Administra√ß√£o P√∫blica - Bolsa Fam√≠lia

Este reposit√≥rio cont√©m os c√≥digos e recursos desenvolvidos para o projeto de pesquisa que visa auxiliar a gest√£o do recurso financeiro do Bolsa Fam√≠lia utilizando t√©cnicas de aprendizado de m√°quina.

![Static Badge](https://img.shields.io/badge/Status-Em_Desenvolvimento-blue)

## üéØ Objetivo do Projeto

O objetivo deste projeto √© desenvolver e avaliar um modelo de classifica√ß√£o que possa prever se uma fam√≠lia se enquadra como benefici√°ria do Bolsa Fam√≠lia com base em um conjunto de dados desindetificado com informa√ß√µes a respeito do Cadastro √önico.

## üìù Atividades Propostas

- [x] Coleta e organiza√ß√£o dos dados
- [x] Pr√©-processamento dos dados
- [ ] Desenvolvimento de modelos de Machine Learning
  - [x] Random Forest
  - [x] Suport Vector Machine (SVM)
  - [x] K-Nearest Neighbors (KNN)
  - [ ] Recurrent Neural Networks (RNN)
  - [x] XGBoost
- [ ] Refatora√ß√£o da limpeza dos dados
- [ ] An√°lise de impacto das melhores caracter√≠sticas

## üóÇÔ∏è Estrutura do Reposit√≥rio

O reposit√≥rio est√° dividido em pastas relacionadas as entregas solicitadas em cada etapa do projeto, seguindo a seguinte estrutura√ß√£o:

```
projeto-administracao-publica
‚îú‚îÄ BolsaFamilia/
‚îú‚îÄ CadUnico/
‚îÇ  ‚îú‚îÄ BasesCompletas/
‚îÇ  ‚îú‚îÄ BasesPB/
‚îÇ  ‚îú‚îÄ BasesRN/
‚îÇ  ‚îú‚îÄ BasesRNPB/
‚îÇ  ‚îú‚îÄ KNN/
‚îÇ  ‚îÇ  ‚îú‚îÄ TrainningPB.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ TrainningRN.ipynb
‚îÇ  ‚îú‚îÄ RandomForest/
‚îÇ  ‚îÇ  ‚îú‚îÄ TrainningPB.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ TrainningRN.ipynb
‚îÇ  ‚îú‚îÄ SVM/
‚îÇ  ‚îÇ  ‚îú‚îÄ TrainningPB.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ TrainningRN.ipynb
‚îÇ  ‚îú‚îÄ XGBoost/
‚îÇ  ‚îÇ  ‚îú‚îÄ TrainningPB.ipynb
‚îÇ  ‚îÇ  ‚îî‚îÄ TrainningRN.ipynb
‚îÇ  ‚îú‚îÄ cadunico_2018.ipynb
‚îÇ  ‚îî‚îÄ cadunico_2018.ipynb
‚îú‚îÄ NovoBolsaFamiliaTransparencia/
‚îú‚îÄ readme.md
‚îî‚îÄ .gitignore
```

## üöÄ Tecnologias Utilizadas

As tecnologias utilizadas no projeto s√£o as seguintes:

[![python](https://img.shields.io/badge/Python-3.9-3776AB.svg?style=flat&logo=python&logoColor=white)](https://www.python.org)
[![jupyter](https://img.shields.io/badge/Jupyter-Lab-F37626.svg?style=flat&logo=Jupyter)](https://jupyterlab.readthedocs.io/en/stable)

## üõ†Ô∏è Como utilizar

Para utilizar a aplica√ß√£o siga esses passos:

- i. Clone o reposit√≥rio:

  > git clone https://github.com/mariabandeira/AdministracaoPublica

- ii. Instale os pacotes necess√°rios do Python:

  > pip install -r requirements.txt

- iii. Execute os Jupyters Notebooks.

## ‚≠ê Resultados

### ü§ñ T√©cinicas de Machine Learning

Neste projeto, utilizamos diferentes algoritmos de Machine Learning. As t√©cnicas aplicadas incluem:

- Random Forest (RF): um modelo baseado em √°rvores de decis√£o que utiliza um conjunto de √°rvores para melhorar a precis√£o da predi√ß√£o e reduzir o overfitting;
- Support Vector Machine (SVM): algoritmo que busca um hiperplano √≥timo para separar as classes no espa√ßo de caracter√≠sticas, sendo eficaz especialmente para problemas com dados n√£o linearmente separ√°veis;
- K-Nearest Neighbors (KNN): m√©todo baseado na proximidade entre os dados, classificando um novo ponto com base nas classes dos seus vizinhos mais pr√≥ximos;
- XGBoost: uma t√©cnica avan√ßada de boosting que melhora a precis√£o e efici√™ncia computacional, sendo amplamente utilizada para competi√ß√µes e aplica√ß√µes do mundo real.

### üêò Resultados RN

No contexto do Rio Grande do Norte, foi utilizada uma amostra com 336.639 registros com um toltal de 31 colunas. Os dados foram processados, resultando na remo√ß√£o de colunas com uma alta quantidade de valores ausentes, ou que n√£o se encontravam em um formato adequado para o treinamento de modelos de ML (como colunas com datas, por exemplo), al√©m disso, registros duplicados tamb√©m foram removidos, visando uma melhoria do processo de treinamento. A partir disso, a amostra resultante apresentou `296.062 registros` e um total de `16 colunas`, as quais incluem:

- `classif`;
- `vlr_renda_media_fam`;
- `cod_local_domic_fam`;
- `qtd_comodos_domic_fam`;
- `qtd_comodos_dormitorio_fam`;
- `cod_material_piso_fam`;
- `cod_material_domic_fam`;
- `cod_agua_canalizada_fam`;
- `cod_abaste_agua_domic_fam`;
- `cod_banheiro_domic_fam`;
- `cod_destino_lixo_domic_fam`;
- `cod_iluminacao_domic_fam `;
- `cod_calcamento_domic_fam`;
- `ind_familia_quilombola_fam`;
- `marc_pbf`;
- `qtde_pessoas`;

#### Modelos treinados com todas as caracter√≠sticas

<table>
        <thead>
            <tr>
                <th rowspan="2">Modelo</th>
                <th rowspan="2">Acur√°cia</th>
                <th colspan="2">Precis√£o</th>
                <th colspan="2">Recall</th>
                <th colspan="2">F1-Score</th>
            </tr>
            <tr>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>KNN</td>
                <td>82%</td>
                <td>0.86</td>
                <td>0.79</td>
                <td>0.70</td>
                <td>0.91</td>
                <td>0.77</td>
                <td>0.84</td>
            </tr>
            <tr>
                <td>SVM</td>
                <td>89%</td>
                <td>0.91</td>
                <td>0.87</td>
                <td>0.82</td>
                <td>0.94</td>
                <td>0.86</td>
                <td>0.90</td>
            </tr>
            <tr>
                <td>RF</td>
                <td>90%</td>
                <td>0.94</td>
                <td>0.87</td>
                <td>0.82</td>
                <td>0.96</td>
                <td>0.87</td>
                <td>0.91</td>
            </tr>
            <tr>
                <td>XGBoost</td>
                <td>90%</td>
                <td>0.93</td>
                <td>0.88</td>
                <td>0.83</td>
                <td>0.95</td>
                <td>0.97</td>
                <td>0.91</td>
            </tr>
            <tr>
                <td>RNN</td>
                <td>89%</td>
                <td>0.91</td>
                <td>0.88</td>
                <td>0.83</td>
                <td>0.94</td>
                <td>0.87</td>
                <td>0.91</td>
            </tr>
        </tbody>
</table>

#### Modelos treinados com as melhores caracter√≠sticas

<table>
        <thead>
            <tr>
                <th rowspan="2">Modelo</th>
                <th rowspan="2">Acur√°cia</th>
                <th colspan="2">Precis√£o</th>
                <th colspan="2">Recall</th>
                <th colspan="2">F1-Score</th>
            </tr>
            <tr>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>KNN</td>
                <td>83%</td>
                <td>0.81</td>
                <td>0.75</td>
                <td>0.82</td>
                <td>0.84</td>
                <td>0.82</td>
                <td>0.85</td>
            </tr>
            <tr>
                <td>SVM</td>
                <td>89%</td>
                <td>0.93</td>
                <td>0.86</td>
                <td>0.80</td>
                <td>0.96</td>
                <td>0.86</td>
                <td>0.91</td>
            </tr>
            <tr>
                <td>RF</td>
                <td>90%</td>
                <td>0.93</td>
                <td>0.88</td>
                <td>0.82</td>
                <td>0.96</td>
                <td>0.87</td>
                <td>0.91</td>
            </tr>
            <tr>
                <td>XGBoost</td>
                <td>90%</td>
                <td>0.93</td>
                <td>0.88</td>
                <td>0.82</td>
                <td>0.95</td>
                <td>0.87</td>
                <td>0.91</td>
            </tr>
          <tr>
                <td>RNN</td>
                <td>90%</td>
                <td>0.92</td>
                <td>0.88</td>
                <td>0.83</td>
                <td>0.95</td>
                <td>0.87</td>
                <td>0.91</td>
            </tr>
        </tbody>
</table>

### ü¶à Resultados PB

No contexto da Par√≠ba, foi utilizada uma amostra com 435.656 registros com um toltal de 31 colunas. Os dados foram processados, resultando na remo√ß√£o de colunas com uma alta quantidade de valores ausentes, ou que n√£o se encontravam em um formato adequado para o treinamento de modelos de ML (como colunas com datas, por exemplo), al√©m disso, registros duplicados tamb√©m foram removidos, visando uma melhoria do processo de treinamento. A partir disso, a amostra resultante apresentou `182.184 registros` e um total de `18 colunas`, as quais incluem:

- `classf`;
- `vlr_renda_media_fam`;
- `cod_local_domic_fam`;
- `cod_especie_domic_fam`;       
- `qtd_comodos_domic_fam`;
- `qtd_comodos_dormitorio_fam`;
- `cod_material_piso_fam`;
- `cod_material_domic_fam`;
- `cod_agua_canalizada_fam`
- `cod_abaste_agua_domic_fam`;
- `cod_banheiro_domic_fam`;
- `cod_destino_lixo_domic_fam`;
- `cod_iluminacao_domic_fam`;
- `cod_calcamento_domic_fam`;
- `cod_familia_indigena_fam`;
- `ind_familia_quilombola_fam`;
- `qtde_pessoas`;
- `marc_pbf`;

#### Modelos treinados com todas as caracter√≠sticas

<table>
        <thead>
            <tr>
                <th rowspan="2">Modelo</th>
                <th rowspan="2">Acur√°cia</th>
                <th colspan="2">Precis√£o</th>
                <th colspan="2">Recall</th>
                <th colspan="2">F1-Score</th>
            </tr>
            <tr>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>KNN</td>
                <td>87%</td>
                <td>0.87</td>
                <td>0.87</td>
                <td>0.74</td>
                <td>0.94</td>
                <td>0.80</td>
                <td>0.90</td>
            </tr>
            <tr>
                <td>SVM</td>
                <td>90%</td>
                <td>0.91</td>
                <td>0.90</td>
                <td>0.80</td>
                <td>0.96</td>
                <td>0.85</td>
                <td>0.93</td>
            </tr>
            <tr>
                <td>RF</td>
                <td>91%</td>
                <td>0.94</td>
                <td>0.89</td>
                <td>0.78</td>
                <td>0.97</td>
                <td>0.85</td>
                <td>0.93</td>
            </tr>
            <tr>
                <td>XGBoost</td>
                <td>87%</td>
                <td>0.87</td>
                <td>0.86</td>
                <td>0.77</td>
                <td>0.93</td>
                <td>0.82</td>
                <td>0.90</td>
            </tr>
           <tr>
                <td>RNN</td>
                <td>87%</td>
                <td>0.88</td>
                <td>0.86</td>
                <td>0.76</td>
                <td>0.93</td>
                <td>0.81</td>
                <td>0.89</td>
            </tr>
        </tbody>
</table>

#### Modelos treinados com as melhores caracter√≠sticas

<table>
        <thead>
            <tr>
                <th rowspan="2">Modelo</th>
                <th rowspan="2">Acur√°cia</th>
                <th colspan="2">Precis√£o</th>
                <th colspan="2">Recall</th>
                <th colspan="2">F1-Score</th>
            </tr>
            <tr>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
                <th>Classe 0</th>
                <th>Classe 1</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>KNN</td>
                <td>70%</td>
                <td>0.54</td>
                <td>0.92</td>
                <td>0.90</td>
                <td>0.58</td>
                <td>0.68</td>
                <td>0.71</td>
            </tr>
            <tr>
                <td>SVM</td>
                <td>90%</td>
                <td>0.93</td>
                <td>0.89</td>
                <td>0.78</td>
                <td>0.97</td>
                <td>0.85</td>
                <td>0.93</td>
            </tr>
            <tr>
                <td>RF</td>
                <td>90%</td>
                <td>0.92</td>
                <td>0.89</td>
                <td>0.79</td>
                <td>0.96</td>
                <td>0.85</td>
                <td>0.93</td>
            </tr>
            <tr>
                <td>XGBoost</td>
                <td>87%</td>
                <td>0.88</td>
                <td>0.86</td>
                <td>0.76</td>
                <td>0.93</td>
                <td>0.82</td>
                <td>0.90</td>
            </tr>
           <tr>
                <td>RNN</td>
                <td>87%</td>
                <td>0.89</td>
                <td>0.86</td>
                <td>0.75</td>
                <td>0.94</td>
                <td>0.81</td>
                <td>0.90</td>
            </tr>
        </tbody>
</table>

## üë• Equipe do Projeto

#### Discentes

- Luiz Fernando da Cunha Silva (UFERSA)
- Maria Eduarda Bandeira (UFPB)

#### Docentes Orientadoras

- Prof. Dra. Samara Martins Nascimento (UFERSA)
- Prof. Dra. Ver√¥nica Maria Lima Silva (UFPB)
